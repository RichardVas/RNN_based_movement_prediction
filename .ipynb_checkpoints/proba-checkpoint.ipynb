{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03dbe33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LSTM import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debcd265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97ab6658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X [[[1.         0.782918  ]\n",
      "  [1.         0.782918  ]\n",
      "  [1.         0.782918  ]\n",
      "  [0.8291874  0.9325288 ]\n",
      "  [0.8291874  0.9325288 ]\n",
      "  [0.6523234  1.        ]\n",
      "  [0.6523234  1.        ]\n",
      "  [0.6523234  1.        ]\n",
      "  [0.49331895 0.97621423]\n",
      "  [0.49331895 0.97621423]]\n",
      "\n",
      " [[1.         0.782918  ]\n",
      "  [1.         0.782918  ]\n",
      "  [0.8291874  0.9325288 ]\n",
      "  [0.8291874  0.9325288 ]\n",
      "  [0.6523234  1.        ]\n",
      "  [0.6523234  1.        ]\n",
      "  [0.6523234  1.        ]\n",
      "  [0.49331895 0.97621423]\n",
      "  [0.49331895 0.97621423]\n",
      "  [0.49331895 0.97621423]]\n",
      "\n",
      " [[1.         0.782918  ]\n",
      "  [0.8291874  0.9325288 ]\n",
      "  [0.8291874  0.9325288 ]\n",
      "  [0.6523234  1.        ]\n",
      "  [0.6523234  1.        ]\n",
      "  [0.6523234  1.        ]\n",
      "  [0.49331895 0.97621423]\n",
      "  [0.49331895 0.97621423]\n",
      "  [0.49331895 0.97621423]\n",
      "  [0.31912595 0.82960576]]\n",
      "\n",
      " [[0.8291874  0.9325288 ]\n",
      "  [0.8291874  0.9325288 ]\n",
      "  [0.6523234  1.        ]\n",
      "  [0.6523234  1.        ]\n",
      "  [0.6523234  1.        ]\n",
      "  [0.49331895 0.97621423]\n",
      "  [0.49331895 0.97621423]\n",
      "  [0.49331895 0.97621423]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]]\n",
      "\n",
      " [[0.8291874  0.9325288 ]\n",
      "  [0.6523234  1.        ]\n",
      "  [0.6523234  1.        ]\n",
      "  [0.6523234  1.        ]\n",
      "  [0.49331895 0.97621423]\n",
      "  [0.49331895 0.97621423]\n",
      "  [0.49331895 0.97621423]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]]\n",
      "\n",
      " [[0.6523234  1.        ]\n",
      "  [0.6523234  1.        ]\n",
      "  [0.6523234  1.        ]\n",
      "  [0.49331895 0.97621423]\n",
      "  [0.49331895 0.97621423]\n",
      "  [0.49331895 0.97621423]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]]\n",
      "\n",
      " [[0.6523234  1.        ]\n",
      "  [0.6523234  1.        ]\n",
      "  [0.49331895 0.97621423]\n",
      "  [0.49331895 0.97621423]\n",
      "  [0.49331895 0.97621423]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]]\n",
      "\n",
      " [[0.6523234  1.        ]\n",
      "  [0.49331895 0.97621423]\n",
      "  [0.49331895 0.97621423]\n",
      "  [0.49331895 0.97621423]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.11171857 0.3150025 ]]\n",
      "\n",
      " [[0.49331895 0.97621423]\n",
      "  [0.49331895 0.97621423]\n",
      "  [0.49331895 0.97621423]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.11171857 0.3150025 ]\n",
      "  [0.11171857 0.3150025 ]]\n",
      "\n",
      " [[0.49331895 0.97621423]\n",
      "  [0.49331895 0.97621423]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.11171857 0.3150025 ]\n",
      "  [0.11171857 0.3150025 ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.49331895 0.97621423]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.31912595 0.82960576]\n",
      "  [0.11171857 0.3150025 ]\n",
      "  [0.11171857 0.3150025 ]\n",
      "  [0.         0.        ]\n",
      "  [0.         0.        ]]]\n",
      "Y [[0.49331895 0.97621423]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.11171857 0.3150025 ]\n",
      " [0.11171857 0.3150025 ]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]]\n",
      "X.shape (11, 10, 2) Y.shape (11, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#series = np.arange(100)\n",
    "#series = np.array([[i,i] for i in range(11)])\n",
    "path = np.array([[883.1654052734375, 266.6562194824219, 919.376708984375, 287.6607971191406], [883.1654052734375, 266.6562194824219, 919.376708984375, 287.6607971191406], [883.1654052734375, 266.6562194824219, 919.376708984375, 287.6607971191406], [871.0694580078125, 267.8135070800781, 903.6286010742188, 287.8651123046875], [871.0694580078125, 267.8135070800781, 903.6286010742188, 287.8651123046875], [858.5449829101562, 268.3354187011719, 891.9022216796875, 288.3023681640625], [858.5449829101562, 268.3354187011719, 891.9022216796875, 288.3023681640625], [858.5449829101562, 268.3354187011719, 891.9022216796875, 288.3023681640625], [847.2852172851562, 268.15142822265625, 879.994140625, 287.5618591308594], [847.2852172851562, 268.15142822265625, 879.994140625, 287.5618591308594], [847.2852172851562, 268.15142822265625, 879.994140625, 287.5618591308594], [834.9498901367188, 267.0173645019531, 867.0343017578125, 285.5546875], [834.9498901367188, 267.0173645019531, 867.0343017578125, 285.5546875], [834.9498901367188, 267.0173645019531, 867.0343017578125, 285.5546875], [834.9498901367188, 267.0173645019531, 867.0343017578125, 285.5546875], [834.9498901367188, 267.0173645019531, 867.0343017578125, 285.5546875], [820.2625122070312, 263.0367431640625, 850.6278076171875, 281.7377014160156], [820.2625122070312, 263.0367431640625, 850.6278076171875, 281.7377014160156], [812.3512573242188, 260.60009765625, 842.8633422851562, 280.06134033203125], [812.3512573242188, 260.60009765625, 842.8633422851562, 280.06134033203125], [812.3512573242188, 260.60009765625, 842.8633422851562, 280.06134033203125]])\n",
    "series = []\n",
    "for i in path:\n",
    "    series.append([i[0],i[1]])\n",
    "scaler = MinMaxScaler()\n",
    "series = scaler.fit_transform(series)\n",
    "T = 10\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for t in range(len(series)-T):\n",
    "    x = series[t:t+T]\n",
    "    X.append(x)\n",
    "    y = series[t+T]\n",
    "    Y.append(y)\n",
    "    \n",
    "X = np.array(X).reshape(-1,T,2).astype(np.float32)\n",
    "Y = np.array(Y).reshape(-1,2).astype(np.float32)\n",
    "N = len(X)\n",
    "print('X',X)\n",
    "print('Y',Y)\n",
    "print('X.shape',X.shape, 'Y.shape',Y.shape)\n",
    "    \n",
    "series = np.array(series)\n",
    "series = series.T\n",
    "#print(series)\n",
    "plt.scatter(series[0],series[1])\n",
    "plt.plot(series[0],series[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74aec4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (0, 10, 1) Y.shape (0, 1)\n"
     ]
    }
   ],
   "source": [
    "T = 10\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for t in range(len(series)-T):\n",
    "    x = series[t:t+T]\n",
    "    X.append(x)\n",
    "    y = series[t+T]\n",
    "    Y.append(y)\n",
    "    \n",
    "X = np.array(X).reshape(-1,T,1).astype(np.float32)\n",
    "Y = np.array(Y).reshape(-1,1).astype(np.float32)\n",
    "N = len(X)\n",
    "print('X.shape',X.shape, 'Y.shape',Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cef35c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X [[[883.1654  266.65622]\n",
      "  [883.1654  266.65622]\n",
      "  [883.1654  266.65622]\n",
      "  [871.06946 267.8135 ]\n",
      "  [871.06946 267.8135 ]\n",
      "  [858.545   268.33542]\n",
      "  [858.545   268.33542]\n",
      "  [858.545   268.33542]\n",
      "  [847.2852  268.15143]\n",
      "  [847.2852  268.15143]]\n",
      "\n",
      " [[883.1654  266.65622]\n",
      "  [883.1654  266.65622]\n",
      "  [871.06946 267.8135 ]\n",
      "  [871.06946 267.8135 ]\n",
      "  [858.545   268.33542]\n",
      "  [858.545   268.33542]\n",
      "  [858.545   268.33542]\n",
      "  [847.2852  268.15143]\n",
      "  [847.2852  268.15143]\n",
      "  [847.2852  268.15143]]\n",
      "\n",
      " [[883.1654  266.65622]\n",
      "  [871.06946 267.8135 ]\n",
      "  [871.06946 267.8135 ]\n",
      "  [858.545   268.33542]\n",
      "  [858.545   268.33542]\n",
      "  [858.545   268.33542]\n",
      "  [847.2852  268.15143]\n",
      "  [847.2852  268.15143]\n",
      "  [847.2852  268.15143]\n",
      "  [834.9499  267.01736]]\n",
      "\n",
      " [[871.06946 267.8135 ]\n",
      "  [871.06946 267.8135 ]\n",
      "  [858.545   268.33542]\n",
      "  [858.545   268.33542]\n",
      "  [858.545   268.33542]\n",
      "  [847.2852  268.15143]\n",
      "  [847.2852  268.15143]\n",
      "  [847.2852  268.15143]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]]\n",
      "\n",
      " [[871.06946 267.8135 ]\n",
      "  [858.545   268.33542]\n",
      "  [858.545   268.33542]\n",
      "  [858.545   268.33542]\n",
      "  [847.2852  268.15143]\n",
      "  [847.2852  268.15143]\n",
      "  [847.2852  268.15143]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]]\n",
      "\n",
      " [[858.545   268.33542]\n",
      "  [858.545   268.33542]\n",
      "  [858.545   268.33542]\n",
      "  [847.2852  268.15143]\n",
      "  [847.2852  268.15143]\n",
      "  [847.2852  268.15143]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]]\n",
      "\n",
      " [[858.545   268.33542]\n",
      "  [858.545   268.33542]\n",
      "  [847.2852  268.15143]\n",
      "  [847.2852  268.15143]\n",
      "  [847.2852  268.15143]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]]\n",
      "\n",
      " [[858.545   268.33542]\n",
      "  [847.2852  268.15143]\n",
      "  [847.2852  268.15143]\n",
      "  [847.2852  268.15143]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]\n",
      "  [820.2625  263.03674]]\n",
      "\n",
      " [[847.2852  268.15143]\n",
      "  [847.2852  268.15143]\n",
      "  [847.2852  268.15143]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]\n",
      "  [820.2625  263.03674]\n",
      "  [820.2625  263.03674]]\n",
      "\n",
      " [[847.2852  268.15143]\n",
      "  [847.2852  268.15143]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]\n",
      "  [820.2625  263.03674]\n",
      "  [820.2625  263.03674]\n",
      "  [812.35126 260.6001 ]]\n",
      "\n",
      " [[847.2852  268.15143]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]\n",
      "  [834.9499  267.01736]\n",
      "  [820.2625  263.03674]\n",
      "  [820.2625  263.03674]\n",
      "  [812.35126 260.6001 ]\n",
      "  [812.35126 260.6001 ]]]\n",
      "Y [[847.2852  268.15143]\n",
      " [834.9499  267.01736]\n",
      " [834.9499  267.01736]\n",
      " [834.9499  267.01736]\n",
      " [834.9499  267.01736]\n",
      " [834.9499  267.01736]\n",
      " [820.2625  263.03674]\n",
      " [820.2625  263.03674]\n",
      " [812.35126 260.6001 ]\n",
      " [812.35126 260.6001 ]\n",
      " [812.35126 260.6001 ]]\n"
     ]
    }
   ],
   "source": [
    "print('X',X)\n",
    "print('Y',Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04a419c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0000, 0.7829],\n",
      "         [1.0000, 0.7829],\n",
      "         [1.0000, 0.7829],\n",
      "         [0.8292, 0.9325],\n",
      "         [0.8292, 0.9325],\n",
      "         [0.6523, 1.0000],\n",
      "         [0.6523, 1.0000],\n",
      "         [0.6523, 1.0000],\n",
      "         [0.4933, 0.9762],\n",
      "         [0.4933, 0.9762]],\n",
      "\n",
      "        [[1.0000, 0.7829],\n",
      "         [1.0000, 0.7829],\n",
      "         [0.8292, 0.9325],\n",
      "         [0.8292, 0.9325],\n",
      "         [0.6523, 1.0000],\n",
      "         [0.6523, 1.0000],\n",
      "         [0.6523, 1.0000],\n",
      "         [0.4933, 0.9762],\n",
      "         [0.4933, 0.9762],\n",
      "         [0.4933, 0.9762]],\n",
      "\n",
      "        [[1.0000, 0.7829],\n",
      "         [0.8292, 0.9325],\n",
      "         [0.8292, 0.9325],\n",
      "         [0.6523, 1.0000],\n",
      "         [0.6523, 1.0000],\n",
      "         [0.6523, 1.0000],\n",
      "         [0.4933, 0.9762],\n",
      "         [0.4933, 0.9762],\n",
      "         [0.4933, 0.9762],\n",
      "         [0.3191, 0.8296]],\n",
      "\n",
      "        [[0.8292, 0.9325],\n",
      "         [0.8292, 0.9325],\n",
      "         [0.6523, 1.0000],\n",
      "         [0.6523, 1.0000],\n",
      "         [0.6523, 1.0000],\n",
      "         [0.4933, 0.9762],\n",
      "         [0.4933, 0.9762],\n",
      "         [0.4933, 0.9762],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296]],\n",
      "\n",
      "        [[0.8292, 0.9325],\n",
      "         [0.6523, 1.0000],\n",
      "         [0.6523, 1.0000],\n",
      "         [0.6523, 1.0000],\n",
      "         [0.4933, 0.9762],\n",
      "         [0.4933, 0.9762],\n",
      "         [0.4933, 0.9762],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296]],\n",
      "\n",
      "        [[0.6523, 1.0000],\n",
      "         [0.6523, 1.0000],\n",
      "         [0.6523, 1.0000],\n",
      "         [0.4933, 0.9762],\n",
      "         [0.4933, 0.9762],\n",
      "         [0.4933, 0.9762],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296]],\n",
      "\n",
      "        [[0.6523, 1.0000],\n",
      "         [0.6523, 1.0000],\n",
      "         [0.4933, 0.9762],\n",
      "         [0.4933, 0.9762],\n",
      "         [0.4933, 0.9762],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296]],\n",
      "\n",
      "        [[0.6523, 1.0000],\n",
      "         [0.4933, 0.9762],\n",
      "         [0.4933, 0.9762],\n",
      "         [0.4933, 0.9762],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.1117, 0.3150]],\n",
      "\n",
      "        [[0.4933, 0.9762],\n",
      "         [0.4933, 0.9762],\n",
      "         [0.4933, 0.9762],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.1117, 0.3150],\n",
      "         [0.1117, 0.3150]],\n",
      "\n",
      "        [[0.4933, 0.9762],\n",
      "         [0.4933, 0.9762],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.1117, 0.3150],\n",
      "         [0.1117, 0.3150],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.4933, 0.9762],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.3191, 0.8296],\n",
      "         [0.1117, 0.3150],\n",
      "         [0.1117, 0.3150],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]], device='cuda:0') torch.Size([11, 10, 2])\n",
      "tensor([[0.4933, 0.9762],\n",
      "        [0.3191, 0.8296],\n",
      "        [0.3191, 0.8296],\n",
      "        [0.3191, 0.8296],\n",
      "        [0.3191, 0.8296],\n",
      "        [0.3191, 0.8296],\n",
      "        [0.1117, 0.3150],\n",
      "        [0.1117, 0.3150],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000]], device='cuda:0') torch.Size([11, 2])\n",
      "epoch:  0 loss: tensor(1.0107, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:  100 loss: tensor(0.0325, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:  200 loss: tensor(0.0151, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:  300 loss: tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:  400 loss: tensor(0.0069, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:  500 loss: tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:  600 loss: tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:  700 loss: tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:  800 loss: tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:  900 loss: tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:  1000 loss: tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:  1100 loss: tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:  1200 loss: tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:  1300 loss: tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:  1400 loss: tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:  1500 loss: tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:  1600 loss: tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:  1700 loss: tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:  1800 loss: tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:  1900 loss: tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:  2000 loss: tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:  2100 loss: tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:  2200 loss: tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:  2300 loss: tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:  2400 loss: tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import autograd, gru\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from dataset import *\n",
    "from time import time\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "\n",
    "\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(GRU, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            self.input_size,\n",
    "            self.hidden_size,\n",
    "            self.num_layers,\n",
    "            batch_first=True,\n",
    "            # dropout  = 1\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # len(x) = batches = 1 , seqlen\n",
    "        # print(len(x))\n",
    "        h0 = torch.zeros(self.num_layers, len(x), self.hidden_size).to(dev)\n",
    "       # c0 = torch.zeros(self.num_layers, len(x), self.hidden_size).to(dev)\n",
    "\n",
    "        out, hn = self.gru(x,h0)\n",
    "\n",
    "        # return out\n",
    "        #return self.fc(out)\n",
    "        return self.fc(out[:,-1,:])\n",
    "\n",
    "class TrackerGRU():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.model = GRU(2, 4, 1).to(dev)\n",
    "        self.scaler = MinMaxScaler()\n",
    "\n",
    "        self.seq_len = 11\n",
    "        self.input_feature = 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        pass\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        losses = []\n",
    "        # writer = SummaryWriter()\n",
    "        torch.manual_seed(1)\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.01)\n",
    "\n",
    "        loss = nn.MSELoss()\n",
    "\n",
    "\n",
    "        input_tensor = torch.from_numpy(X).to(dev)\n",
    "\n",
    "        print(input_tensor, input_tensor.shape)\n",
    "        target_tensor = torch.from_numpy(Y).to(dev)\n",
    "        print(target_tensor, target_tensor.shape)\n",
    "        epoch = 2500\n",
    "        for i in range(epoch):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            x = self.model.forward(input_tensor)\n",
    "           # print(x)\n",
    "            single_loss = loss(x, target_tensor)\n",
    "\n",
    "            #losses.append(single_loss)\n",
    "\n",
    "            if (i % 100 == 0):\n",
    "                print('epoch: ', i, 'loss:', single_loss)\n",
    "            # backward, hogy \"visszafejti \"\n",
    "\n",
    "            single_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, input_vector):\n",
    "        start = time()\n",
    "        self.model.eval()\n",
    "        print('eredeti',input_vector)\n",
    "\n",
    "\n",
    "        \n",
    "        #scalerr.fit(input_vector)\n",
    "     #   input_vector =scaler.transform(input_vector)\n",
    "       # print('transformed',input_vector)\n",
    "\n",
    "        #  print('input_vector',input_vector)\n",
    "      #  input_vector = self.scaler.transform(input_vector)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # assuem that the input is correctly shaped\n",
    "           # inp = self.scaler.fit_transform(input_vector)\n",
    "                                                                    #n bacthes  seqlen  input feat\n",
    "            inp_tensor = torch.FloatTensor(input_vector).reshape(1, len(input_vector), self.input_feature).to(dev)\n",
    "            print(input_vector)\n",
    "            result = self.model.forward(inp_tensor)\n",
    "            #er = scaler.inverse_transform(result.cpu().data.view(-1, 2))\n",
    "            er = data.view(-1, 2)\n",
    "          #  print('b4 inverse scale',er)\n",
    "      #      er = scalerr.inverse_transform(er)\n",
    "\n",
    "            end = time()\n",
    "            # toreturn = (roundToInt(er[-1][0]), roundToInt(er[-1][1]))\n",
    "            # print(toreturn)\n",
    "           # print(er)\n",
    "            \n",
    "            print('eredmeny',er[-1], 'timetopred',end-start)\n",
    "            \n",
    "            return er[-1]\n",
    "\n",
    "            # return toreturn\n",
    "\n",
    "proba = TrackerGRU()\n",
    "proba.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6f060d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eredeti [[1.         0.782918  ]\n",
      " [1.         0.782918  ]\n",
      " [1.         0.782918  ]\n",
      " [0.8291874  0.9325288 ]\n",
      " [0.8291874  0.9325288 ]\n",
      " [0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]]\n",
      "[[1.         0.782918  ]\n",
      " [1.         0.782918  ]\n",
      " [1.         0.782918  ]\n",
      " [0.8291874  0.9325288 ]\n",
      " [0.8291874  0.9325288 ]\n",
      " [0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]]\n",
      "eredmeny tensor([0.3652, 0.8978]) timetopred 0.3136923313140869\n",
      "eredeti [[1.         0.782918  ]\n",
      " [1.         0.782918  ]\n",
      " [0.8291874  0.9325288 ]\n",
      " [0.8291874  0.9325288 ]\n",
      " [0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]]\n",
      "[[1.         0.782918  ]\n",
      " [1.         0.782918  ]\n",
      " [0.8291874  0.9325288 ]\n",
      " [0.8291874  0.9325288 ]\n",
      " [0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]]\n",
      "eredmeny tensor([0.3641, 0.8952]) timetopred 0.004965543746948242\n",
      "eredeti [[1.         0.782918  ]\n",
      " [0.8291874  0.9325288 ]\n",
      " [0.8291874  0.9325288 ]\n",
      " [0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.31912595 0.82960576]]\n",
      "[[1.         0.782918  ]\n",
      " [0.8291874  0.9325288 ]\n",
      " [0.8291874  0.9325288 ]\n",
      " [0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.31912595 0.82960576]]\n",
      "eredmeny tensor([0.3620, 0.8534]) timetopred 0.0\n",
      "eredeti [[0.8291874  0.9325288 ]\n",
      " [0.8291874  0.9325288 ]\n",
      " [0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]]\n",
      "[[0.8291874  0.9325288 ]\n",
      " [0.8291874  0.9325288 ]\n",
      " [0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]]\n",
      "eredmeny tensor([0.3584, 0.8503]) timetopred 0.0\n",
      "eredeti [[0.8291874  0.9325288 ]\n",
      " [0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]]\n",
      "[[0.8291874  0.9325288 ]\n",
      " [0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]]\n",
      "eredmeny tensor([0.3545, 0.8419]) timetopred 0.0049974918365478516\n",
      "eredeti [[0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]]\n",
      "[[0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]]\n",
      "eredmeny tensor([0.3179, 0.7640]) timetopred 0.0\n",
      "eredeti [[0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]]\n",
      "[[0.6523234  1.        ]\n",
      " [0.6523234  1.        ]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]]\n",
      "eredmeny tensor([0.1085, 0.4250]) timetopred 0.0\n",
      "eredeti [[0.6523234  1.        ]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.11171857 0.3150025 ]]\n",
      "[[0.6523234  1.        ]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.11171857 0.3150025 ]]\n",
      "eredmeny tensor([0.0953, 0.2229]) timetopred 0.004998445510864258\n",
      "eredeti [[0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.11171857 0.3150025 ]\n",
      " [0.11171857 0.3150025 ]]\n",
      "[[0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.11171857 0.3150025 ]\n",
      " [0.11171857 0.3150025 ]]\n",
      "eredmeny tensor([-0.0208, -0.0133]) timetopred 0.0\n",
      "eredeti [[0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.11171857 0.3150025 ]\n",
      " [0.11171857 0.3150025 ]\n",
      " [0.         0.        ]]\n",
      "[[0.49331895 0.97621423]\n",
      " [0.49331895 0.97621423]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.11171857 0.3150025 ]\n",
      " [0.11171857 0.3150025 ]\n",
      " [0.         0.        ]]\n",
      "eredmeny tensor([0.0154, 0.0201]) timetopred 0.0\n",
      "eredeti [[0.49331895 0.97621423]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.11171857 0.3150025 ]\n",
      " [0.11171857 0.3150025 ]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]]\n",
      "[[0.49331895 0.97621423]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.31912595 0.82960576]\n",
      " [0.11171857 0.3150025 ]\n",
      " [0.11171857 0.3150025 ]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]]\n",
      "eredmeny tensor([ 0.0268, -0.0064]) timetopred 0.004999876022338867\n"
     ]
    }
   ],
   "source": [
    "predicted=[]\n",
    "for i in X:\n",
    "    predicted.append(proba.predict(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "693fafd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [73]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predicted \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m predicted \u001b[38;5;241m=\u001b[39m predicted\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(predicted[\u001b[38;5;241m0\u001b[39m],predicted[\u001b[38;5;241m1\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "predicted = np.array(predicted)\n",
    "predicted = predicted.T\n",
    "plt.plot(predicted[0],predicted[1], label='pred')\n",
    "plt.plot(series[0],series[1],label = 'og')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69dbf23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
