{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba28b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from Pred import *\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import mean_absolute_percentage_error as MAPE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "from time import time\n",
    "from grapher import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03de5805",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('measurement/saved_dictionary.pkl', 'rb') as f:\n",
    "    loaded_dict = pickle.load(f)\n",
    "\n",
    "print(loaded_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d8690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in loaded_dict:\n",
    "    print(key,loaded_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11c6cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalutation_model = Predictor()\n",
    "print(evalutation_model.predict4([[1,1],[2,2],[3,3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e293f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predDict = defaultdict(list)\n",
    "\n",
    "ogCords = defaultdict(list)\n",
    "evalutation_model = Predictor()\n",
    "for k,v in loaded_dict.items():\n",
    "  #  print(k)\n",
    "    tmp = []\n",
    "    ogCords = []\n",
    "    predictedValues = []\n",
    "    #if(k == 4):\n",
    "    for i in v:\n",
    "        tmp.append([i[0],i[1]])\n",
    "        if(len(tmp)>=10):\n",
    "            start = time()\n",
    "            out = evalutation_model.predict4(tmp[-10:])\n",
    "            #predictedValues.append(out)\n",
    "            predDict[k].append(out)\n",
    "            end = time()\n",
    "    ogCords=tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279adcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(predDict)\n",
    "print(ogCords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec10769",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in loaded_dict:\n",
    "    if(len(loaded_dict[key])>=10):\n",
    "        viz = Grapher()\n",
    "        print(key,loaded_dict[key])\n",
    "        viz.addArray(loaded_dict[key])\n",
    "        viz.displayGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f735c1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in loaded_dict:\n",
    "    if(len(loaded_dict[key])>=10):\n",
    "        \n",
    "        #print(key,loaded_dict[key])\n",
    "        tmp = np.array(loaded_dict[key])\n",
    "        \n",
    "        latest10 = tmp[-10:]\n",
    "        tmp = tmp.T\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "        fig.suptitle('Real and Predicted values of {}'.format(key))\n",
    "        ax1.plot(tmp[0], tmp[1])\n",
    "        ax2.plot(tmp[0], tmp[1])\n",
    "       # plt.savefig('real_predicted/{}.png'.format(key))     \n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e27710",
   "metadata": {},
   "outputs": [],
   "source": [
    "predDict = defaultdict(list)\n",
    "for key in loaded_dict:\n",
    "    tmp = []\n",
    "    for curr in loaded_dict[key]:\n",
    "        tmp.append([curr[0],curr[1]])\n",
    "        if(len(tmp)>=10):\n",
    "            predicted_value = evalutation_model.predict4(tmp[-10:])\n",
    "            predDict[key].append(predicted_value)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0e2dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display real life values against their predicted counterparts\n",
    "for key in loaded_dict:\n",
    "    if(len(loaded_dict[key])>=10):\n",
    "        \n",
    "        #print(key,loaded_dict[key])\n",
    "        real = np.array(loaded_dict[key])\n",
    "        real = real.T\n",
    "        \n",
    "        predicted = np.array(predDict[key])\n",
    "        predicted = predicted.T\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "        fig.suptitle('Real and Predicted values of {}'.format(key))\n",
    "        ax1.plot(real[0], real[1])\n",
    "        ax1.scatter(real[0], real[1])\n",
    "        ax2.plot(predicted[0], predicted[1])\n",
    "        ax2.scatter(predicted[0], predicted[1])\n",
    "        plt.savefig('real_predicted/{}.png'.format(key))     \n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6821ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measure the difference between prediction and expected values:\n",
    "MAPE_values = []\n",
    "prediction_rtt = []\n",
    "pairs = []\n",
    "for key in loaded_dict:\n",
    "    tmp = []\n",
    "    for curr in loaded_dict[key]:\n",
    "        tmp.append([curr[0],curr[1]])\n",
    "        if(len(tmp)==13):\n",
    "            start_rtt = time()\n",
    "            predicted_value = evalutation_model.predict4(tmp[-10:])\n",
    "            end_rtt = time()\n",
    "            prediction_rtt.append((end_rtt-start_rtt))\n",
    "            expected_value = tmp[-1]\n",
    "            pairs.append([predicted_value,expected_value])\n",
    "            tmp.pop(0)\n",
    "for pair in pairs:\n",
    "    print('0',pair[0],'1',pair[1])\n",
    "    MAPE_val = MAPE(pair[1],pair[0])\n",
    "    #print('MAPE',MAPE_val)\n",
    "   # print('MSE',MSE(pair[0],pair[1]))\n",
    "   # print('MAE',MAE(pair[0],pair[1]))\n",
    "    MAPE_values.append(MAPE_val)\n",
    "#print('MAPE',MAPE(pairs[0],pairs[1]))\n",
    "#print('MSE',MSE(pairs[0],pairs[1]))\n",
    "#print('MAE',MAE(pairs[0],pairs[1]))\n",
    "\n",
    "#print(MAPE_values)\n",
    "plt.plot(MAPE_values)\n",
    "plt.title('mean absolute percentage error')\n",
    "plt.savefig('mape.jpg')\n",
    "plt.show()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cd4ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the measured response time for a prediction\n",
    "mean = np.mean(prediction_rtt)\n",
    "plt.plot(prediction_rtt)\n",
    "plt.title('Mean prediction time:   {}'.format(mean))\n",
    "plt.savefig('mean_rtt.jpg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70e1188",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb61e73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
